{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/andre/PycharmProjects/stocks\n"
     ]
    }
   ],
   "source": [
    "cd /home/andre/PycharmProjects/stocks/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import os \n",
    "import sys\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "import talib as ta\n",
    "import datetime\n",
    "from Tools.util import progressbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Tools import Meta5_Ibov_Load as meta5load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta5filepath = \"/home/andre/.wine/drive_c/Program Files/Rico MetaTrader 5/MQL5/Files\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(meta5filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "must load metatrader 5 *.mt5bin files\n"
     ]
    }
   ],
   "source": [
    "meta5load.Set_Data_Path(meta5filepath, meta5filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't load data: missing *RTM1.mt5bin files!\n"
     ]
    }
   ],
   "source": [
    "masterdf = meta5load.Load_Meta5_Data(suffix='RTM1.mt5bin', cleandays=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Vectors Ready for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# backup things\n",
    "Xo = X\n",
    "Yo = Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.values.astype(np.float32) # due Float tensors\n",
    "y = Y.values.astype(np.int64) # due Cross Entropy Loss requeires Tensor Long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(504816, 157)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(504816,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change here if you wish OPTIONS\n",
    "# shift=60\n",
    "nforecast=60\n",
    "nvalidation=nforecast # to validate the model prior prediction\n",
    "ntraining = 5*8*60 # 5*8 hours before for training - 1 week or 8 hours\n",
    "nwindow = nvalidation+nforecast+ntraining "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(256*30)/(5*8*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2400\n",
      "64\n",
      "60\n"
     ]
    }
   ],
   "source": [
    "print(ntraining)\n",
    "print(batch_size)\n",
    "print(nvalidation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Xo.skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "begin = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple non-parallel version for testings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GeForce GTX 1060'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "th.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from torch.optim import lr_scheduler\n",
    "device = th.device(\"cuda\" if th.cuda.is_available() else \"cpu\")\n",
    "input_size = X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TorchModelPredict(model, X):\n",
    "    y_prob = model(X)     \n",
    "    y_pred = th.argmax(y_prob, 1)\n",
    "    y_pred = y_pred.to(\"cpu\")\n",
    "    return y_prob, y_pred.data.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Using Multiple threads on GPU by CUDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Need to work on this someday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_shuffle(X, y, size):\n",
    "    \"\"\"better use the dataset api in the future\"\"\"\n",
    "    i = np.random.randint(X.shape[0]-size)\n",
    "    return X[i:i+size], y[i:i+size]\n",
    "\n",
    "def fastTrainTorchNet(X, y, X_s, y_s, input_size, model=None, nepochs=30, device=\"cuda\", \n",
    "                  batch_size=256, verbose=True):\n",
    "    \"\"\"\n",
    "    X, y         : vectors for training\n",
    "    X_s, y_s     : vector for validation (scoring the model)\n",
    "    \n",
    "    the best model with smaller error in validation will be returned\n",
    "    after the nepochs of training\n",
    "    \n",
    "    \"\"\"\n",
    "    if model == None:\n",
    "        model = th.nn.Sequential(th.nn.Linear(input_size, 1024), th.nn.ReLU(), th.nn.Dropout(.1),\n",
    "                                 th.nn.Linear(1024,280), th.nn.ReLU(), th.nn.Dropout(.3),\n",
    "                                 th.nn.Linear(280, 70), th.nn.ReLU(),  th.nn.Dropout(.05),\n",
    "                                 th.nn.Linear(70, 2), th.nn.Softmax(dim=1)) # dim == 1 collumns add up to 1 probability\n",
    "        criterion = th.nn.CrossEntropyLoss()\n",
    "        model = model.to(device)\n",
    "        #weight_decay regularization not applied\n",
    "        optimizer = th.optim.Adam(model.parameters(), lr=0.1) # learning rate optimal\n",
    "    # Decay LR by a factor of 0.1 every 10 epochs\n",
    "    scheduler = lr_scheduler.StepLR(optimizer, step_size=15, gamma=0.1)\n",
    "    \n",
    "    best_model = None\n",
    "    best_lossv = 1000.\n",
    "    best_error = 100.\n",
    "    for t in range(nepochs):\n",
    "        X_t, y_t = tensor_shuffle(X, y, batch_size)        \n",
    "        y_pred = model(X_t)         \n",
    "        lossy = criterion(y_pred, y_t)\n",
    "        optimizer.zero_grad()\n",
    "        lossy.backward()\n",
    "        optimizer.step()\n",
    "        model.eval()\n",
    "        y_pred = th.argmax(y_pred, 1)         # calculate error complement of accuracy\n",
    "        error_train = th.nn.functional.mse_loss(\n",
    "            y_pred.float(), y_t.float())\n",
    "        y_pred = model(X_s)          # on validation set\n",
    "        lossv = criterion(y_pred, y_s)\n",
    "        y_pred = th.argmax(y_pred, 1)\n",
    "        error_validation = th.nn.functional.mse_loss(\n",
    "            y_pred.float(), y_s.float())\n",
    "        if lossv < best_lossv: # now loss for validation is smaller\n",
    "            best_lossv = lossv     # lets save this network\n",
    "            best_errorv = error_validation\n",
    "            best_errort = error_train\n",
    "            best_model = copy.deepcopy(model.state_dict()) # save the actual weights\n",
    "        \n",
    "        if verbose:\n",
    "            if t%int(nepochs/5) == 0: \n",
    "                # on the loss values could apply a kind of normalization due the fact that they \n",
    "                # don't have same size of samples BUT just BEAR ON MIND\n",
    "                # loss error on validation set absolute value has NOTHING to do with\n",
    "                # with the absolute value of the training set\n",
    "                print(\"iteration : {:6d} l training: {:.2f} l validation: {:.2f}\"\n",
    "                      \" Err trainging :{:.2f}  Err validation ; {:.3f}\".format(\n",
    "                      t, lossy, lossv, error_train, error_validation))\n",
    "\n",
    "        model.train()                \n",
    "        scheduler.step()\n",
    "\n",
    "    # return the best model in the validation and the accuracy\n",
    "    best_errorv = best_errorv.to(\"cpu\").item()\n",
    "    best_errort = best_errort.to(\"cpu\").item()\n",
    "    model.load_state_dict(best_model)\n",
    "    #print(best_errort, best_errorv)\n",
    "    # return the model and accuracy of training and validation\n",
    "    return model, best_model, best_errort, best_errorv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_shuffle(X, y, size):\n",
    "    \"\"\"better use the dataset api in the future\"\"\"\n",
    "    i = np.random.randint(X.shape[0]-size)\n",
    "    return X[i:i+size], y[i:i+size]\n",
    "\n",
    "def TrainTorchNet(X, y, X_s, y_s, input_size, model=None, nepochs=30, device=\"cuda\", \n",
    "                  batch_size=256, verbose=True):\n",
    "    \"\"\"\n",
    "    X, y         : vectors for training\n",
    "    X_s, y_s     : vector for validation (scoring the model)\n",
    "    \n",
    "    the best model with smaller error in validation will be returned\n",
    "    after the nepochs of training\n",
    "    \n",
    "    \"\"\"\n",
    "    if model == None:\n",
    "        model = th.nn.Sequential(th.nn.Linear(input_size, 1024), th.nn.ReLU(), th.nn.Dropout(.1),\n",
    "                                 th.nn.Linear(1024,280), th.nn.ReLU(), th.nn.Dropout(.3),\n",
    "                                 th.nn.Linear(280, 70), th.nn.ReLU(),  th.nn.Dropout(.05),\n",
    "                                 th.nn.Linear(70, 2), th.nn.Softmax(dim=1)) # dim == 1 collumns add up to 1 probability\n",
    "        criterion = th.nn.CrossEntropyLoss()\n",
    "        model = model.to(device)\n",
    "\n",
    "        #weight_decay regularization not applied\n",
    "        optimizer = th.optim.Adam(model.parameters(), lr=0.1) # learning rate optimal\n",
    "        \n",
    "        #optimizer.to(device)\n",
    "\n",
    "    # Decay LR by a factor of 0.1 every 10 epochs\n",
    "    scheduler = lr_scheduler.StepLR(optimizer, step_size=15, gamma=0.1)\n",
    "    \n",
    "    best_model = None\n",
    "    best_lossv = 1000.\n",
    "    best_error = 100.\n",
    "\n",
    "    for t in range(nepochs):\n",
    "        \n",
    "        X_t, y_t = tensor_shuffle(X, y, batch_size)        \n",
    "        \n",
    "        y_pred = model(X_t)         \n",
    "        # Compute and print loss\n",
    "        lossy = criterion(y_pred, y_t)\n",
    "        # Zero gradients, perform a backward pass, and update the weights.\n",
    "        optimizer.zero_grad()\n",
    "        lossy.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # could also store best score and try\n",
    "        # to continue training from that like tensorflow checkpoints        \n",
    "        # Model Evaluation\n",
    "        model.eval()\n",
    "        # calculate error complement of accuracy\n",
    "        # on training set\n",
    "        y_pred = th.argmax(y_pred, 1)\n",
    "        error_train = th.nn.functional.mse_loss(\n",
    "            y_pred.float(), y_t.float())\n",
    "\n",
    "        # calculate percentage accuracy\n",
    "        # on validation set\n",
    "        y_pred = model(X_s) \n",
    "        lossv = criterion(y_pred, y_s)\n",
    "        y_pred = th.argmax(y_pred, 1)\n",
    "        error_validation = th.nn.functional.mse_loss(\n",
    "            y_pred.float(), y_s.float())\n",
    "        \n",
    "        ### error on validation set next 60 samples / minutes\n",
    "        ### todo: better tecniques of early stopping, early stopping\n",
    "        ### is a regularization so other techinques might be better?\n",
    "        ### or easier?\n",
    "        if lossv < best_lossv: # now loss for validation is smaller\n",
    "            # lets save this network\n",
    "            best_lossv = lossv\n",
    "            best_errorv = error_validation\n",
    "            best_errort = error_train\n",
    "            best_model = copy.deepcopy(model.state_dict()) # save the actual weights\n",
    "        \n",
    "        if verbose:\n",
    "            if t%int(nepochs/5) == 0: \n",
    "                # on the loss values could apply a kind of normalization due the fact that they \n",
    "                # don't have same size of samples BUT just BEAR ON MIND\n",
    "                # loss error on validation set absolute value has NOTHING to do with\n",
    "                # with the absolute value of the training set\n",
    "                print(\"iteration : {:6d} l training: {:.2f} l validation: {:.2f}\"\n",
    "                      \" Err trainging :{:.2f}  Err validation ; {:.3f}\".format(\n",
    "                      t, lossy, lossv, error_train, error_validation))\n",
    "\n",
    "        model.train()                \n",
    "        scheduler.step()\n",
    "\n",
    "    # return the best model in the validation and the accuracy\n",
    "    best_errorv = best_errorv.to(\"cpu\").item()\n",
    "    best_errort = best_errort.to(\"cpu\").item()\n",
    "    model.load_state_dict(best_model)\n",
    "    #print(best_errort, best_errorv)\n",
    "    # return the model and accuracy of training and validation\n",
    "    return model, best_errort, best_errorv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"Executor of prediction\"\"\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sys\n",
    "\n",
    "# change here if you wish OPTIONS\n",
    "# shift=60\n",
    "nforecast=60\n",
    "nvalidation=nforecast # to validate the model prior prediction\n",
    "ntraining = 5*8*60 # 8 hours before for training\n",
    "nwindow = nvalidation+nforecast+ntraining \n",
    "\n",
    "\n",
    "def Slide_Predictions(X, y, index, input_size, verbose=False, device='cuda'):\n",
    "    \"\"\"\n",
    "    Backtesting:\n",
    "    Make predictions with a sliding window.    \n",
    "    \"\"\"\n",
    "    size = len(X)\n",
    "    # number of possible predictions with data size : size\n",
    "    # because forecast are allways array of forecasts\n",
    "    # defined by the shift made\n",
    "    nshifts = size-(ntraining+nvalidation+nforecast)     \n",
    "    \n",
    "    if nshifts <= 0:\n",
    "        print('somethings is wrong, array of data too small')\n",
    "        print('minimum size is training+validation+forecast for 1 prediction')\n",
    "        return\n",
    "    \n",
    "    if verbose:\n",
    "        print('maximum number of predictions is: ', nshifts)    \n",
    "    \n",
    "    # sliding window with step of one sample shift   \n",
    "    prediction_book = pd.DataFrame(index=np.arange(nshifts), columns=['tindex', 'buy', 'score'])\n",
    "    \n",
    "    # all to cuda memory\n",
    "    X = th.tensor(X).to(device)\n",
    "    y = th.tensor(y).to(device)\n",
    "    \n",
    "    for i in progressbar(range(nshifts)):  \n",
    "        \n",
    "        index_ = index[i:i+nwindow].copy()        \n",
    "        # training samples are the first ones\n",
    "        X_t = X[i:i+ntraining]\n",
    "        y_t = y[i:i+ntraining]        \n",
    "\n",
    "        # control samples for scoring (validation of the model)\n",
    "        # SCORE using the nforecast samples just after the window       \n",
    "        X_s = X[i+ntraining:i+ntraining+nvalidation]\n",
    "        y_s = y[i+ntraining:i+ntraining+nvalidation]\n",
    "\n",
    "        # predict on the last nforecast samples\n",
    "        X_p = X[i+ntraining+nvalidation:i+ntraining+nvalidation+nforecast]        \n",
    "\n",
    "        # return mode, accuracy \n",
    "        clfmodel, errort, errorv = TrainTorchNet(X_t, y_t, X_s, y_s, \n",
    "                                                       input_size, device=device, verbose=False)\n",
    "\n",
    "        # accurary of the model if higher than 90% we can predict\n",
    "        score = errorv           \n",
    "        \n",
    "        if verbose:\n",
    "            print(i, \" errort : \", errort, \" errorv: \",errorv)\n",
    "        \n",
    "        # we cannot predict unless the model is 90%+ accurate\n",
    "        # accurate on validation. on training we accept 70%+\n",
    "        if errorv > 0.1 or errort > 0.3: \n",
    "            del clfmodel\n",
    "            continue    \n",
    "\n",
    "        probability, prediction = TorchModelPredict(clfmodel, X_p)        \n",
    "        \n",
    "        down = abs(prediction.sum()-len(prediction))/len(prediction)\n",
    "        up = abs(1-down)\n",
    "\n",
    "        if up > 0.9 or down > 0.9: # only if certain by 90% that will go up or down\n",
    "            # where will it be bought in time\n",
    "            # allways +5 minutes after prediction\n",
    "            tindex = index_[-nforecast+5]\n",
    "            buy = up > down\n",
    "            if buy: # buy\n",
    "                buy = 1\n",
    "            else: # sell\n",
    "                buy = -1\n",
    "            prediction_book.iloc[i] = [tindex, buy, score]\n",
    "            #print(prediction_book.iloc[i])            \n",
    "            \n",
    "        del clfmodel\n",
    "        \n",
    "    return prediction_book\n",
    "\n",
    "# splitting data to guarantee overlapping multiprocessing\n",
    "# split data in a batch with limits [start:end]\n",
    "def paralel_Slide_Predictions_Up_Down(Xtrain, ytrain, sIndex, start, end):    \n",
    "    X = Xtrain[start:end]\n",
    "    y = ytrain[start:end]\n",
    "    input_size = Xtrain.shape[1]\n",
    "    index = sIndex[start:end]        \n",
    "    prediction_book = Slide_Predictions(X.copy(), y.copy(), index.copy(), input_size)    \n",
    "    # save recommended orders from starti to endi\n",
    "    prediction_book.dropna(inplace=True) # due preallocated size there are nan samples\n",
    "    return prediction_book\n",
    "    \n",
    "def paralel_batch_slices(nprocesses, datasize, nwindow):\n",
    "    \"\"\"\n",
    "    create batch slice indexes for paralel processing\n",
    "    should write test function for this\n",
    "    altough it is perfectly working\n",
    "    \"\"\"\n",
    "    batch_size = int(np.floor((datasize-nwindow)/nprocesses))\n",
    "    nmiss = (datasize-nwindow-batch_size*nprocesses) # samples to complete the non integer division\n",
    "    # last batch will have more sample to complete the non integer division\n",
    "    slices = np.array([i*batch_size for i in range(nprocesses)])\n",
    "    # each batch must have the previous sample size of training + forecast window\n",
    "    istarts = slices\n",
    "    iends = slices[1:] + nwindow\n",
    "    iends = np.append(iends, datasize)\n",
    "    # first and last batch have different size of samples\n",
    "    print('batch starts ', istarts)\n",
    "    print('batch ends ', iends)\n",
    "    print('batch sizes ', iends-istarts) \n",
    "    batches = zip(istarts, iends)\n",
    "    return batches"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Remember LOSS includes probability of classification (cross-class) \n",
    "is not as simple as eclidian error (ms_loss).\n",
    "\n",
    "So even if MSLOSS might be smaller what matters \n",
    "more as metric is the true cross entropy loss. \n",
    "Specially because MSLOSS is calculated over the clipped array of classs probibilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "limit = len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "504816"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[################################################################################] 502296/502296\n",
      "CPU times: user 9h 24min 6s, sys: 7min 48s, total: 9h 31min 54s\n",
      "Wall time: 9h 30min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "prediction_book = Slide_Predictions(X[:limit], y[:limit], Yo.index[:limit], input_size, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_book.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05318769611105829"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prediction_book)/limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tindex</th>\n",
       "      <th>buy</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2013-07-11 10:31:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2013-07-11 10:32:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2013-07-11 10:44:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2013-07-11 10:50:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2013-07-11 10:54:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>2013-07-11 10:56:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>2013-07-11 12:24:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>2013-07-11 12:28:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>2013-07-11 12:37:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>2013-07-11 12:53:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>2013-07-11 12:58:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>2013-07-11 13:02:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>2013-07-11 13:14:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>2013-07-11 13:22:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>2013-07-11 13:42:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>2013-07-11 14:19:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>2013-07-11 14:24:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>2013-07-11 14:27:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>2013-07-11 14:40:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>2013-07-11 14:46:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>2013-07-11 14:53:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>2013-07-11 14:57:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>2013-07-11 16:27:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>2013-07-12 10:52:00</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>2013-07-12 11:33:00</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>2013-07-12 11:34:00</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>2013-07-12 11:36:00</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734</th>\n",
       "      <td>2013-07-15 10:36:00</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>2013-07-15 10:43:00</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>2013-07-15 10:46:00</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501152</th>\n",
       "      <td>2018-07-24 15:09:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501158</th>\n",
       "      <td>2018-07-24 15:15:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501159</th>\n",
       "      <td>2018-07-24 15:16:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501163</th>\n",
       "      <td>2018-07-24 15:20:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501166</th>\n",
       "      <td>2018-07-24 15:23:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501167</th>\n",
       "      <td>2018-07-24 15:24:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501172</th>\n",
       "      <td>2018-07-24 15:29:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501173</th>\n",
       "      <td>2018-07-24 15:30:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501182</th>\n",
       "      <td>2018-07-24 15:39:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501306</th>\n",
       "      <td>2018-07-25 10:58:00</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501469</th>\n",
       "      <td>2018-07-25 13:41:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501474</th>\n",
       "      <td>2018-07-25 13:46:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501485</th>\n",
       "      <td>2018-07-25 13:57:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501490</th>\n",
       "      <td>2018-07-25 14:02:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501494</th>\n",
       "      <td>2018-07-25 14:06:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501635</th>\n",
       "      <td>2018-07-25 16:27:00</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501683</th>\n",
       "      <td>2018-07-26 10:29:00</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501824</th>\n",
       "      <td>2018-07-26 12:51:00</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501836</th>\n",
       "      <td>2018-07-26 13:03:00</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501838</th>\n",
       "      <td>2018-07-26 13:05:00</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501852</th>\n",
       "      <td>2018-07-26 13:19:00</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501929</th>\n",
       "      <td>2018-07-26 14:36:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502021</th>\n",
       "      <td>2018-07-26 16:08:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502023</th>\n",
       "      <td>2018-07-26 16:10:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502117</th>\n",
       "      <td>2018-07-27 11:01:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502120</th>\n",
       "      <td>2018-07-27 11:04:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502124</th>\n",
       "      <td>2018-07-27 11:08:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502137</th>\n",
       "      <td>2018-07-27 11:21:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502140</th>\n",
       "      <td>2018-07-27 11:24:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502141</th>\n",
       "      <td>2018-07-27 11:25:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26850 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     tindex buy      score\n",
       "20      2013-07-11 10:31:00   1          0\n",
       "21      2013-07-11 10:32:00   1          0\n",
       "33      2013-07-11 10:44:00   1          0\n",
       "39      2013-07-11 10:50:00   1          0\n",
       "43      2013-07-11 10:54:00   1          0\n",
       "45      2013-07-11 10:56:00   1          0\n",
       "127     2013-07-11 12:24:00   1  0.0833333\n",
       "131     2013-07-11 12:28:00   1  0.0333333\n",
       "140     2013-07-11 12:37:00   1  0.0333333\n",
       "151     2013-07-11 12:53:00   1  0.0333333\n",
       "155     2013-07-11 12:58:00   1  0.0333333\n",
       "159     2013-07-11 13:02:00   1  0.0333333\n",
       "170     2013-07-11 13:14:00   1  0.0333333\n",
       "176     2013-07-11 13:22:00   1          0\n",
       "190     2013-07-11 13:42:00   1          0\n",
       "217     2013-07-11 14:19:00   1          0\n",
       "222     2013-07-11 14:24:00   1          0\n",
       "225     2013-07-11 14:27:00   1          0\n",
       "237     2013-07-11 14:40:00   1          0\n",
       "243     2013-07-11 14:46:00   1          0\n",
       "250     2013-07-11 14:53:00   1          0\n",
       "254     2013-07-11 14:57:00   1          0\n",
       "344     2013-07-11 16:27:00   1       0.05\n",
       "414     2013-07-12 10:52:00  -1  0.0833333\n",
       "454     2013-07-12 11:33:00  -1          0\n",
       "455     2013-07-12 11:34:00  -1          0\n",
       "457     2013-07-12 11:36:00  -1          0\n",
       "734     2013-07-15 10:36:00  -1  0.0333333\n",
       "740     2013-07-15 10:43:00  -1  0.0333333\n",
       "743     2013-07-15 10:46:00  -1  0.0833333\n",
       "...                     ...  ..        ...\n",
       "501152  2018-07-24 15:09:00   1  0.0333333\n",
       "501158  2018-07-24 15:15:00   1  0.0333333\n",
       "501159  2018-07-24 15:16:00   1  0.0333333\n",
       "501163  2018-07-24 15:20:00   1  0.0333333\n",
       "501166  2018-07-24 15:23:00   1  0.0333333\n",
       "501167  2018-07-24 15:24:00   1  0.0333333\n",
       "501172  2018-07-24 15:29:00   1  0.0166667\n",
       "501173  2018-07-24 15:30:00   1  0.0166667\n",
       "501182  2018-07-24 15:39:00   1  0.0166667\n",
       "501306  2018-07-25 10:58:00  -1  0.0833333\n",
       "501469  2018-07-25 13:41:00   1          0\n",
       "501474  2018-07-25 13:46:00   1          0\n",
       "501485  2018-07-25 13:57:00   1          0\n",
       "501490  2018-07-25 14:02:00   1          0\n",
       "501494  2018-07-25 14:06:00   1          0\n",
       "501635  2018-07-25 16:27:00  -1          0\n",
       "501683  2018-07-26 10:29:00  -1  0.0833333\n",
       "501824  2018-07-26 12:51:00  -1          0\n",
       "501836  2018-07-26 13:03:00  -1          0\n",
       "501838  2018-07-26 13:05:00  -1          0\n",
       "501852  2018-07-26 13:19:00  -1          0\n",
       "501929  2018-07-26 14:36:00   1  0.0666667\n",
       "502021  2018-07-26 16:08:00   1          0\n",
       "502023  2018-07-26 16:10:00   1          0\n",
       "502117  2018-07-27 11:01:00   1       0.05\n",
       "502120  2018-07-27 11:04:00   1  0.0333333\n",
       "502124  2018-07-27 11:08:00   1  0.0333333\n",
       "502137  2018-07-27 11:21:00   1  0.0333333\n",
       "502140  2018-07-27 11:24:00   1       0.05\n",
       "502141  2018-07-27 11:25:00   1  0.0666667\n",
       "\n",
       "[26850 rows x 3 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_book.to_pickle('allyears_PETR4_prediction_CUDA_NN_EMA120min_shift120_RFy_90_70_percent_pytorch.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Need to reinstall CUDA so multiprocessing GPU works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Using multiprocessing for Pytorch + CUDA\n",
    "Joblib wont work!  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is not working\n",
      "batch starts  [     0 251178]\n",
      "batch ends  [253698 504876]\n",
      "batch sizes  [253698 253698]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-1:\n",
      "Process Process-2:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/andre/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/andre/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/andre/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/andre/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-45-f9b3fa76b674>\", line 100, in paralel_Slide_Predictions_Up_Down\n",
      "    prediction_book = Slide_Predictions(X.copy(), y.copy(), index.copy(), input_size)\n",
      "  File \"<ipython-input-45-f9b3fa76b674>\", line 100, in paralel_Slide_Predictions_Up_Down\n",
      "    prediction_book = Slide_Predictions(X.copy(), y.copy(), index.copy(), input_size)\n",
      "  File \"<ipython-input-45-f9b3fa76b674>\", line 38, in Slide_Predictions\n",
      "    X = th.tensor(X).to(device)\n",
      "  File \"<ipython-input-45-f9b3fa76b674>\", line 38, in Slide_Predictions\n",
      "    X = th.tensor(X).to(device)\n",
      "RuntimeError: cuda runtime error (3) : initialization error at /opt/conda/conda-bld/pytorch_1532579805626/work/aten/src/THC/THCCachingAllocator.cpp:507\n",
      "RuntimeError: cuda runtime error (3) : initialization error at /opt/conda/conda-bld/pytorch_1532579805626/work/aten/src/THC/THCCachingAllocator.cpp:507\n"
     ]
    }
   ],
   "source": [
    "import torch.multiprocessing as mp\n",
    "from multiprocessing import set_start_method\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    try:\n",
    "        set_start_method('spawn')\n",
    "    except RuntimeError:\n",
    "        print(\"is not working\")\n",
    "        pass\n",
    "    num_processes = 2\n",
    "    processes = []\n",
    "    batches = paralel_batch_slices(num_processes, len(X), nwindow)\n",
    "    for start, end in batches:\n",
    "        p = mp.Process(target=paralel_Slide_Predictions_Up_Down,\n",
    "                       args=(X, y, yor.index, start, end))\n",
    "        p.start()        \n",
    "        processes.append(p)\n",
    "    for p in processes:\n",
    "        p.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
