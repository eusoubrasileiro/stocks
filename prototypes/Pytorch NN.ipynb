{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/andre/Projects/stocks\n"
     ]
    }
   ],
   "source": [
    "cd '/home/andre/Projects/stocks'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import copy\n",
    "import torch as th\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torch.optim import lr_scheduler\n",
    "import scipy\n",
    "import sys\n",
    "import pandas as pd\n",
    "from Tools.util import progressbar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Vectors Ready for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = pd.read_pickle('X_train_20180823_all_nobuckets_nopercentiles_nostdn.pickle')\n",
    "# Y = pd.read_pickle('Y_train_20180823_all_nobuckets_nopercentiles_nostdn.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import struct\n",
    "import datetime\n",
    "import calendar\n",
    "import time\n",
    "import argparse\n",
    "from Tools.util import progressbar\n",
    "from Tools import prepareData, torchNN\n",
    "from Tools import meta5Ibov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2887 2640\n"
     ]
    }
   ],
   "source": [
    "nwasted = 120+120+7  # number of lost samples due (shift + EMA's + unknown)\n",
    "ntraining = 5*8*60 # 8 hours before for training\n",
    "nscore = 120 # validation samples\n",
    "nforecast = 120 # forecasting/prediction samples\n",
    "nneed = ntraining+nscore+nforecast+nwasted # need number of samples\n",
    "npredict = nscore + nforecast + ntraining # samples for predicting one direction\n",
    "print(nneed, npredict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Symbols loaded:\n",
      "['BBAS3' 'DOL$' 'VALE3' 'ABEV3' 'ITUB4' 'B3SA3' 'BBDC4' 'PETR4' 'WIN@']\n",
      "percent missing:  0.02973624520526797\n"
     ]
    }
   ],
   "source": [
    "# Working Path for Expert Advisor Metatrader 5\n",
    "# Use same path that can be read by the expert advisor\n",
    "datapath = '/home/andre/Projects/stocks/data'\n",
    "os.chdir(datapath)\n",
    "# statistical mean and variance from 2013+2018 used to make data\n",
    "# with variance < 1 and mean close to 0, that is how it works!\n",
    "stocks_stats = pd.read_csv('stocks_stats_2018.csv', index_col=0)\n",
    "# selected columns by backtesting best performance accuracy\n",
    "with open('collumns_selected.txt', 'r') as f: # txt column names divided by spaces\n",
    "    columns = f.read()\n",
    "selected_columns = columns.split(' ')[:-1]\n",
    "#datapath = '/home/andre/.wine/drive_c/Program Files/Rico MetaTrader 5/MQL5/Files'\n",
    "meta5Ibov.setDataPath(datapath, datapath, verbose=False)\n",
    "# don't want masterdf to be reused\n",
    "masterdf = meta5Ibov.loadMeta5Data(suffix='M1.mt5bin',\n",
    "            cleandays=True, preload=False, verbose=True)\n",
    "masterdf = meta5Ibov.simpleColumnNames()\n",
    "percmiss = meta5Ibov.calculateMissing(masterdf)\n",
    "X, y, Xp = prepareData.GetTrainingPredictionVectors(\n",
    "    masterdf.copy(), targetsymbol='PETR4_C', verbose=False,\n",
    "    selected=selected_columns, stats=stocks_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(504995, 148)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#th.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = th.device(\"cuda\" if th.cuda.is_available() else \"cpu\")\n",
    "input_size = X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# limit = len(X)\n",
    "# limit = npredict+10 # 10 predictions \n",
    "# limit = npredict+100\n",
    "# nshifts = X.shape[0] - npredict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "504995"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(504995, 148)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "504995"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'Tools.torchNN' from '/home/andre/Projects/stocks/Tools/torchNN.py'>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(torchNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reproducible results with seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fdf27fbd1f0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch as th\n",
    "import random\n",
    "seed=10\n",
    "np.random.seed(seed)\n",
    "if str(device) == 'cuda':\n",
    "    th.backends.cudnn.deterministic = True\n",
    "random.seed(seed) # pytorch rely on random for weights\n",
    "th.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#limit = 5*8*60*4*3# 3 months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "limit = len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "504995"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[################################################################################] 502355/502355\n",
      "CPU times: user 11h 4min 28s, sys: 9min 35s, total: 11h 14min 4s\n",
      "Wall time: 11h 16min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "prediction_book = torchNN.backtestPredictions(X[:limit], y[:limit], input_size, device, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03712512005069357"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prediction_book)/limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18748"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prediction_book)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_book.to_pickle('PETR4_20180823_all_nobuckets_nopercentiles_no_std_CUDA_NN_EMA120min_shift120_RFy_90_70_percent_pytorch.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Need to reinstall CUDA so multiprocessing GPU works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting data to guarantee overlapping multiprocessing\n",
    "# split data in a batch with limits [start:end]\n",
    "def paralel_Slide_Predictions_Up_Down(Xtrain, ytrain, start, end):    \n",
    "    X = Xtrain[start:end]\n",
    "    y = ytrain[start:end]\n",
    "    input_size = Xtrain.shape[1]\n",
    "    #index = sIndex[start:end]        \n",
    "    prediction_book = Slide_Predictions(X.copy(), y.copy(), input_size)    \n",
    "    # save recommended orders from starti to endi\n",
    "    #prediction_book.dropna(inplace=True) # due preallocated size there are nan samples\n",
    "    return prediction_book\n",
    "    \n",
    "def paralel_batch_slices(nprocesses, datasize, nwindow):\n",
    "    \"\"\"\n",
    "    create batch slice indexes for paralel processing\n",
    "    should write test function for this\n",
    "    altough it is perfectly working\n",
    "    \"\"\"\n",
    "    batch_size = int(np.floor((datasize-nwindow)/nprocesses))\n",
    "    nmiss = (datasize-nwindow-batch_size*nprocesses) # samples to complete the non integer division\n",
    "    # last batch will have more sample to complete the non integer division\n",
    "    slices = np.array([i*batch_size for i in range(nprocesses)])\n",
    "    # each batch must have the previous sample size of training + forecast window\n",
    "    istarts = slices\n",
    "    iends = slices[1:] + nwindow\n",
    "    iends = np.append(iends, datasize)\n",
    "    # first and last batch have different size of samples\n",
    "    print('batch starts ', istarts)\n",
    "    print('batch ends ', iends)\n",
    "    print('batch sizes ', iends-istarts) \n",
    "    batches = zip(istarts, iends)\n",
    "    return batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Using multiprocessing for Pytorch + CUDA\n",
    "Joblib wont work!  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch starts  [     0 249058]\n",
      "batch ends  [251698 500756]\n",
      "batch sizes  [251698 251698]\n"
     ]
    }
   ],
   "source": [
    "import torch.multiprocessing as mp\n",
    "from multiprocessing import set_start_method\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    try:\n",
    "        set_start_method('spawn')\n",
    "    except RuntimeError:\n",
    "        print(\"is not working\")\n",
    "        pass\n",
    "    num_processes = 2\n",
    "    processes = []\n",
    "    batches = paralel_batch_slices(num_processes, len(X), nwindow)\n",
    "    for start, end in batches:\n",
    "        p = mp.Process(target=paralel_Slide_Predictions_Up_Down,\n",
    "                       args=(X, y, start, end))\n",
    "        p.start()        \n",
    "        processes.append(p)\n",
    "    for p in processes:\n",
    "        p.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
